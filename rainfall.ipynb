{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":38},"id":"Ar6nQ8eMu4Ki"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-4569e924-f550-46b6-b2d8-d0b5eba737a3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-4569e924-f550-46b6-b2d8-d0b5eba737a3\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import seaborn as sns\n","from google.colab import files\n","uploaded = files.upload()\n","full_data = pd.read_csv('weatherAUS.csv')\n","full_data.head()\n","full_data.shape\n","full_data.info()\n","full_data['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n","full_data['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)\n","import matplotlib.pyplot as plt\n","fig = plt.figure(figsize = (8,5))\n","full_data.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n","plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n","plt.show()\n","from sklearn.utils import resample\n","no = full_data[full_data.RainTomorrow == 0]\n","yes = full_data[full_data.RainTomorrow == 1]\n","yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n","oversampled = pd.concat([no, yes_oversampled])\n","fig = plt.figure(figsize = (8,5))\n","oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n","plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n","plt.show()\n","# Missing Data Pattern in Training Data\n","\n","sns.heatmap(oversampled.isnull(), cbar=False, cmap='PuBu')\n","total = oversampled.isnull().sum().sort_values(ascending=False)\n","percent = (oversampled.isnull().sum()/oversampled.isnull().count()).sort_values(ascending=False)\n","missing = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n","missing.head(4)\n","oversampled.select_dtypes(include=['object']).columns\n","# Impute categorical var with Mode\n","oversampled['Date'] = oversampled['Date'].fillna(oversampled['Date'].mode()[0])\n","oversampled['Location'] = oversampled['Location'].fillna(oversampled['Location'].mode()[0])\n","oversampled['WindGustDir'] = oversampled['WindGustDir'].fillna(oversampled['WindGustDir'].mode()[0])\n","oversampled['WindDir9am'] = oversampled['WindDir9am'].fillna(oversampled['WindDir9am'].mode()[0])\n","oversampled['WindDir3pm'] = oversampled['WindDir3pm'].fillna(oversampled['WindDir3pm'].mode()[0])\n","# Convert categorical features to continuous features with Label Encoding\n","from sklearn.preprocessing import LabelEncoder\n","lencoders = {}\n","for col in oversampled.select_dtypes(include=['object']).columns:\n","    lencoders[col] = LabelEncoder()\n","    oversampled[col] = lencoders[col].fit_transform(oversampled[col])\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","# Multiple Imputation by Chained Equations\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","MiceImputed = oversampled.copy(deep=True)\n","mice_imputer = IterativeImputer()\n","MiceImputed.iloc[:, :] = mice_imputer.fit_transform(oversampled)\n","# Detecting outliers with IQR\n","Q1 = MiceImputed.quantile(0.25)\n","Q3 = MiceImputed.quantile(0.75)\n","IQR = Q3 - Q1\n","print(IQR)\n","# Removing outliers from the dataset\n","MiceImputed = MiceImputed[~((MiceImputed \u003c (Q1 - 1.5 * IQR)) |(MiceImputed \u003e (Q3 + 1.5 * IQR))).any(axis=1)]\n","MiceImputed.shape\n","# Correlation Heatmap\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","corr = MiceImputed.corr()\n","mask = np.triu(np.ones_like(corr, dtype=np.bool))\n","f, ax = plt.subplots(figsize=(20, 20))\n","cmap = sns.diverging_palette(250, 25, as_cmap=True)\n","sns.heatmap(corr, mask=mask, cmap=cmap, vmax=None, center=0,square=True, annot=True, linewidths=.5, cbar_kws={\"shrink\": .9})\n","sns.pairplot( data=MiceImputed, vars=('MaxTemp','MinTemp','Pressure9am','Pressure3pm', 'Temp9am', 'Temp3pm', 'Evaporation'), hue='RainTomorrow' )\n","# Standardizing data\n","from sklearn import preprocessing\n","r_scaler = preprocessing.MinMaxScaler()\n","r_scaler.fit(MiceImputed)\n","modified_data = pd.DataFrame(r_scaler.transform(MiceImputed), index=MiceImputed.index, columns=MiceImputed.columns)\n","# Feature Importance using Filter Method (Chi-Square)\n","from sklearn.feature_selection import SelectKBest, chi2\n","X = modified_data.loc[:,modified_data.columns!='RainTomorrow']\n","y = modified_data[['RainTomorrow']]\n","selector = SelectKBest(chi2, k=10)\n","selector.fit(X, y)\n","X_new = selector.transform(X)\n","print(X.columns[selector.get_support(indices=True)])\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.ensemble import RandomForestClassifier as rf\n","\n","X = MiceImputed.drop('RainTomorrow', axis=1)\n","y = MiceImputed['RainTomorrow']\n","selector = SelectFromModel(rf(n_estimators=100, random_state=0))\n","selector.fit(X, y)\n","support = selector.get_support()\n","features = X.loc[:,support].columns.tolist()\n","print(features)\n","print(rf(n_estimators=100, random_state=0).fit(X,y).feature_importances_)\n","features = MiceImputed[['Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustDir',\n","                       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n","                       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n","                       'RainToday']]\n","target = MiceImputed['RainTomorrow']\n","\n","# Split into test and train\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=12345)\n","\n","# Normalize Features\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)\n","def plot_roc_cur(fper, tper):\n","    plt.plot(fper, tper, color='orange', label='ROC')\n","    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    plt.show()\n","import time\n","from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score, plot_confusion_matrix, roc_curve, classification_report\n","def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n","    t0=time.time()\n","    if verbose == False:\n","        model.fit(X_train,y_train, verbose=0)\n","    else:\n","        model.fit(X_train,y_train)\n","    y_pred = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    roc_auc = roc_auc_score(y_test, y_pred)\n","    coh_kap = cohen_kappa_score(y_test, y_pred)\n","    time_taken = time.time()-t0\n","    print(\"Accuracy = {}\".format(accuracy))\n","    print(\"ROC Area under Curve = {}\".format(roc_auc))\n","    print(\"Cohen's Kappa = {}\".format(coh_kap))\n","    print(\"Time taken = {}\".format(time_taken))\n","    print(classification_report(y_test,y_pred,digits=5))\n","\n","    probs = model.predict_proba(X_test)\n","    probs = probs[:, 1]\n","    fper, tper, thresholds = roc_curve(y_test, probs)\n","    plot_roc_cur(fper, tper)\n","\n","    plot_confusion_matrix(model, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')\n","\n","    return model, accuracy, roc_auc, coh_kap, time_taken\n","accuracy_scores = [accuracy_lr,accuracy_dt,accuracy_nn,accuracy_rf,accuracy_lgb,accuracy_cb,accuracy_xgb]\n","roc_auc_scores = [roc_auc_lr,roc_auc_dt,roc_auc_nn,roc_auc_rf,roc_auc_lgb,roc_auc_cb,roc_auc_xgb]\n","coh_kap_scores = [coh_kap_lr,coh_kap_dt,coh_kap_nn,coh_kap_rf,coh_kap_lgb,coh_kap_cb,coh_kap_xgb]\n","tt = [tt_lr,tt_dt,tt_nn,tt_rf,tt_lgb,tt_cb,tt_xgb]\n","model_data = {'Model': ['Logistic Regression','Decision Tree','Neural Network','Random Forest','LightGBM','Catboost','XGBoost'],\n","              'Accuracy': accuracy_scores,\n","              'ROC_AUC': roc_auc_scores,\n","              'Cohen_Kappa': coh_kap_scores,\n","              'Time taken': tt}\n","data = pd.DataFrame(model_data)\n","\n","fig, ax1 = plt.subplots(figsize=(12,10))\n","ax1.set_title('Model Comparison: Accuracy and Time taken for execution', fontsize=13)\n","color = 'tab:green'\n","ax1.set_xlabel('Model', fontsize=13)\n","ax1.set_ylabel('Time taken', fontsize=13, color=color)\n","ax2 = sns.barplot(x='Model', y='Time taken', data = data, palette='summer')\n","ax1.tick_params(axis='y')\n","ax2 = ax1.twinx()\n","color = 'tab:red'\n","ax2.set_ylabel('Accuracy', fontsize=13, color=color)\n","ax2 = sns.lineplot(x='Model', y='Accuracy', data = data, sort=False, color=color)\n","ax2.tick_params(axis='y', color=color)\n","fig, ax3 = plt.subplots(figsize=(12,10))\n","ax3.set_title('Model Comparison: Area under ROC and Cohens Kappa', fontsize=13)\n","color = 'tab:blue'\n","ax3.set_xlabel('Model', fontsize=13)\n","ax3.set_ylabel('ROC_AUC', fontsize=13, color=color)\n","ax4 = sns.barplot(x='Model', y='ROC_AUC', data = data, palette='winter')\n","ax3.tick_params(axis='y')\n","ax4 = ax3.twinx()\n","color = 'tab:red'\n","ax4.set_ylabel('Cohen_Kappa', fontsize=13, color=color)\n","ax4 = sns.lineplot(x='Model', y='Cohen_Kappa', data = data, sort=False, color=color)\n","ax4.tick_params(axis='y', color=color)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BomWccCZQzSQ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNd832BrxU8J"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_Q1uRdgCymB"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"1FoFWi1eCzBm"},"source":[]},{"cell_type":"markdown","metadata":{"id":"hgdggKJuwBON"},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM7bNkhz+ppJD4ODl5i3dvl","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}